st_server_base 中的start 是在 st_asio_wrapper_object_pool中 class st_object_pool实现得start。实现start的地方有两处，
还有一处是class st_socket中

-----------i_packer和i_unpacker------------------
1.从i_packer和i_unpacker继承，生成自己的打包解包器；
2.调用inner_packer()和inner_unpacker()修改打包解包器；
inner_packer()实现于class st_socket
class echo_socket : public st_server_socket_base { class st_server_socket_base : public st_tcp_socket_base<
Socket, Packer, Unpacker> { class st_tcp_socket_base:(::inner_unpacker()) public st_socket<Socket, Packer, Unpacker>
::inner_packer(); }}

3.打包解包器应该要支持原始消息的打包（此时只做数据拷贝，不添加任何数据），如果考虑通用性的话。pack_msg接口的最后一个参数用
于表达是否是打原始消息包（即，pack_msg是从send_msg还是从send_native_msg调用的)
字节序问题：转化字节序是为了同一不同的机器对int32四个字节存储顺序不同，而导致数据的误差。字符串作为单字节在网络传播。
网络字节序不会影响传播。

packer.pack_msg() 返回的是std::basic_string 默认的消息格式是：长度(2)+消息内容
4.接收缓存必须放在解包器之内，当收到数据时，st_asio_wrapper会调用解包器的pars解包器应在结果通过msg_can参数返回出去；
inner_unpacker()在class st_tcp_socket_base 中实现.

在st_server_base::accept_handler()中调用client_ptr->start()；(client_ptr = create_object(boost::ref(st_server_base)); 返回client_ptr是什么？？？？？)
-> 调用st_socket::start(), -> 调用st_server_socket_base::do_start(),-> st_tcp_socket_base::do_recv_msg()
中注册异步读事件的回调unpacker::completion_condition和st_tcp_socket_base::recv_handler()
async_read(stream, buffer [, completion] ,handler)：这个方法异步地从一个流读取。结束时其处理方法被调用。
处理方法的格式是：void handler(const boost::system::error_ code & err, size_t bytes)
;。你可以选择指定一个完成处理方法。完成处理方法会在每个read操作调用成功之后调用，然后告诉Boost.Asio 
async_read操作是否完成（如果没有完成，它会继续读取）。它的格式是：size_t completion(const boost::system::error_code& err, 
size_t bytes_transfered) 。当这个完成处理方法返回0时，我们认为read操作完成；如果它返回一个非0值，它表示了下一个async_read_s
ome操作需要从流中读取的字节数。
接收缓存在unpacker::raw_buff 中,completion_condition() 判读读取的长度是否为包中的长度，如果是则调用handler方法.
st_tcp_socket st_tcp_socket_base::recv_handler() 收到消息回调后，以便让unpacker尝试解析消息，
成功解析出来的消息通过msg_can返回。
boost::array<char, MSG_BUFFER_SIZE> raw_buff; ->msg_pos_can ->temp_msg_buffer;
boost::container::list<std::pair<const char*, size_t>> msg_pos_can;
out_container_type(boost::container::list<std::string>) temp_msg_buffer(msg_can);
typedef typename Unpacker::container_type out_container_type;
typedef boost::container::list<msg_type> container_type;
msg_type = std::string


5.调用parse_msg之后，wrapper马上开始下一次数据接收，此时会调用解包器的prepare_next_recv接回一个缓存（boost 的mutable_buffers_1对象
6.重写completion_condition接判断什么时候可以解析消息了（即调用parse_msg），显然，至消息之后，就可以解析了；返回0代表可以解
析消息了，返回其它值代表至少还需要多少字节，才能解析；这些说看一下默认的解包器的实现就清楚了。

一但使用自定义数据结构，二次开发者不得不自己处理粘包，分包，解包，数据缓存等工作，也就是实现自己的打包解包器。关于打包解包
器的更多信息，请参考st_asio_wrapper自带的packer和unpacker。

发送接收消息缓存，以st_tcp_socket为例，st_udp_socket同理
这两个缓存与unpacker里面的缓存概念不一样，unpacker的缓存是boost.asio使用的最原始的缓存，且一般应该是固定大小的，
st_tcp_socket的发送接收消息缓存里面保存的都是消息，可以直接取出来使用而不需要解包的，其大小不定，但有一个最大条数，具体参看教程一。

发送缓存为什么需要，我想不用解释了吧（如果在send_msg中，不缓存消息，而是直接投递async_write会怎样呢？这样的确是不需要发送缓存了，
但多次的async_write投递，会造成包乱序，这几乎是无法解决并且不可容忍的问题，而且投递的async_write数量也是不定的，内存占用不可控，
所以st_tcp_socket采用了发送缓存，每次只投递一个async_write，等到发送成功之后，再投递下一次）。对于接收消息缓存，其实是可以不要的，
重写on_msg，在里面处理消息即可，但这样带来一个问题，st_tcp_socket需要在on_msg之后才投递下一次async_read（同样为了解决乱序问题），
这样消息处理就阻塞了消息接收；为此，采用了接收消息缓存，当收到消息的时候，直接放在缓存里，再在另外的线程中，回调on_msg_handler，
达到了消息处理与消息接收异步的目的。

如果你不想使用接收消息缓存，则重写on_msg，要么马上处理消息，要么将消息拷贝到你自己的缓存中，由你自己的调度线程去分发消息，
最后返回true；对于马上处理消息的情况，一定注意要快速，否则会阻塞下次消息的接收。

如果on_msg返回false（默认返回true），消息将进入st_tcp_socket的接收消息缓存，并在适当的时候，回调on_msg_handle，你可以在这里面处理消息，
并且不会阻塞下次消息的接收（除非所有IO线程都被阻塞，那说明你的线程不够了；IO线程数量请参看第一篇教程中的ST_SERVICE_THREAD_NUM宏）。

st_asio_wrapper保证消息按照顺序发送、接收和分发（on_msg 和 on_msg_handle），所以你完全不用担心消息乱序的问题。
当然，顺序接收得说两句，接收端是不知道发送端的顺序的，所以顺序接收要建立在顺序发送的基础之上。

-------------------四--------------------

在说st_asio_wrapper是否会死锁之前，我们接着教程一再说一下st_tcp_socket（st_udp_socket同理）的on_msg与on_msg_handle的区别,
为什么要有他们俩，各有什么优势：
当st_tcp_socket收到一条完整的消息的时候，它调用on_msg虚函数，那么显然，二次开发者可以重写on_msg，然后在里面处理消息
（处理完之后一定要返回true，原因往下看），如果on_msg返回false，则消息进入st_tcp_socket的消息接收缓存，再通过调度机制（
由boost的io_service.post()生成），异步的从消息接收缓存里面取出消息，然后调用on_msg_handle，二次开发者需要重写它并在里面处理消息。
到此，大家看到了，消息处理有三种方法：
    1.重写on_msg，在里面处理消息，然后返回true；
    2.重写on_msg，什么也不做，直接返回false（重写是因为st_tcp_socket默认的on_msg返回true），再重写on_msg_handle，在里面处理消息；
    3.开启FORCE_TO_USE_MSG_RECV_BUFFER，在这种情况下得到的效果跟方法2完全一样，但效率更高，它不再调用on_msg（此时也没有这个虚函数了），
    而是直接把消息放入消息接收缓存。所以方法3在二次开发者开发的角度，跟方法2是一样的，以下说方法2的时候，统称方法2和方法3。

方法一中，如果处理消息需要1秒，那么在这1秒之内，这个st_tcp_socket将无法接收任何数据，因为要等on_msg返回之后，才会接着接收数据；
on_msg执行期间st_tcp_socket并未发起下一个read,所以st_tcp_socket无法接收任何数据.
方法二中，因为是将消息直接放消息接收缓存，所以on_msg马上就返回了，那么马上就可以接着接收数据了
（如果定义了FORCE_TO_USE_MSG_RECV_BUFFER也一样，根本不调用on_msg）。而on_msg_handle会在另外某个时刻的某个线程中被调用。
很显然，方法二提高了响应时间（对方数据到达己方，己方什么时候开始读取数据，越早就越实时），但会消耗多一点资源（
增加了一个消息接收缓存，多了一次on_msg_handle调度），这是第一个区别；

第二个区别是，如果用不好它，方法一会造成死锁，方法二则不会，纯异步多线程网络编程，还会死锁？——是的，
原因是增加了消息发送缓存，并且限制了缓存大小，请看我分析（这里面说的缓存，都是st_tcp_socket的缓存，不是套接字的缓存，
异步IO下（包括linux的epoll，虽然它不是异步IO），套接字缓存满肯定不会造成阻塞）：

假设我们用上面的方法一，在on_msg中处理消息，假设在处理某一个消息的时候，一下就会产生出足够让消息发送缓存溢出的应答消息量
（压力测试，平时很难遇上，所以大家可能会陌生），此时你在on_msg里面调用safe_send_msg，那么死锁可能就要发生了，
因为对方可能也因为同样的原因也阻塞在on_msg（调用safe_send_msg），此时是不是就像单线程加阻塞模式了呢？A阻塞在on_msg等待自己
的消息发送缓存可用，消息发送缓存要怎样才可用呢，就是A成功发送一部分数据到B，但此时B也阻塞在on_msg，无法返回，也就无法进行
下一次的数据接收（前面讲了，on_msg返回之后，才进行下一次数据接收），那么A也就不可能成功发送数据到B了（这里指的是要成功接收
了才算）；如果你不阻塞在这里，那你怎么办呢，先找个地方把消息缓存住，然后在以后某个适当的时候再调用send_msg？这毫无疑问大大
的提高了编程的难度，何况st_tcp_socket已经有消息发送缓存了，你还得自己再来一个，说不过去，而且你的这个消息发送缓存是不是也
有大小限制的问题，那么是不是也有缓存溢出的问题……，唉，这样就没完没了了！这里大家可能要问，缓存不加限制不就没问题了吗？答案
是肯定不行，当发送方速度大于接收方处理速度时，缓存将无限增长直到内存耗尽！

如果我们用方法二，是怎么避免发送消息缓存溢出的问题的呢？这涉及到两个问题（消息接收缓存和消息发送缓存）：
一，当on_msg返回false的时候，消息进入消息接收缓存，如果缓存溢出，则不进行下一次数据读取（前面说过，on_msg返回之后，
马上接着进行下一次数据接收，是有点问题的，这里说的才是真实的情况），而是在未来的某个时刻再尝试把消息放入接收缓存，
循环这个动作直到所有消息都成功放入消息接收缓存，然后再进行下一次数据接收，这样就避免了消息接收缓存的溢出问题；
二，在on_msg_handle里面处理消息的时候，当然可能会像方法一一样，产生了大量的回应消息，也需要调用safe_send_msg，
那么当消息发送缓存满的时候会怎样呢？由于阻塞在on_msg_handle不会阻塞数据的收发，所以safe_send_msg总会有返回的时候
（因为对方的消息接收没有被阻塞，它总是会接收一些消息，于是会让己方的发送缓存变得可用）

注意，只要不是因为等待缓存可能而阻塞在on_msg（两端都这样），都是没有问题的，大家也不要太害怕，
比如你阻塞在on_msg里面处理自己的业务，或者阻塞在其它地方，比如on_msg_handle或者你自己的线程都是没有问题的。
换句话说，只要不阻塞在service线程里面，或者解除阻塞的条件与本st_socket的缓存可用性无关，就不会造成死锁，
只会有限的阻塞，死锁是无限的阻塞。
更方便简洁但有些暴力的方法是，用can_overflow为true调用send_msg，这个参数是2.1版本新添加的，目的就是不检测缓存溢出问题，
这个就需要二次开发者保证缓存不会达到不可控的直线上升状态，也就是总要有让缓存减少的机制，或者业务本身在达到某个高度之后，
就会下降，这些情况下，都可以让can_overflow为true。

那么推荐的方法是，如果消息是凭空产生的，则调用safe_send_msg，如果消息是因为处理消息而产生的，则调用post_msg，具体请参看教程第五篇。

第三个区别关乎效率，对于方法一，如果你的处理速度足够快，那么其效率要高于方法二，因为消息不需要去消息接收缓存里面绕一圈；
如果你的处理速度比较慢，那么方法二的效率要高于方法一，但高的不多，这种情况下，方法二的主要优点主要还是实时性，前面第一点说过了。
方法二由于使用了接收消息缓存，其工作原理相当于一个电容，如果你的数据流量曲线是一条正弦曲线，且在最高流量时，处理速度慢于数据到达速度，
在最低流量时，处理速度快于数据到达速度，在这种特定的情况下，方法二的效率就会得到更明显的体现，它会把正弦曲线状态的输入，
转化为一条直线输出，达到了消息接收与消息处理都满负荷的运行（在这种情况下，方法一为什么效率明显低于方法二呢？因为在输入速度
快于处理速度的时候，输入被阻塞；当处理速度快于输入速度时，处理被阻塞，就是两个人不齐心，没有忙到一块儿去）。注意，如果你的处理
速度一直低于数据接收速度，那么任何方法都是免不了要被阻塞的，神仙也没办法。
我前面说了这么多，什么死锁啊，阻塞啊，大家不要被吓住，其实绝大多数时候，都是不用考虑这些问题的，不管你用其它什么类库，
或者自己写一个，都会有缓存满的问题，只是其它类库没有说明这些极限情况而已，我在这里提出来，只是想让大家知道有这么一回事。

十一：线程安全性
默认情况下st_service_pump开启8个IO线程，只要线程数量多于1个，那么所有的回调方法（以on开关的虚函数），都是并发的
（除非是明显有顺序关系的，且是同一个st_socket对象的时候，比如同一个对象的每一条消息的on_msg总是在on_msg_handle之前被调用），
具体说来（以on_msg和on_msg_send为例）：对于同一个st_socket（及其子类对象），on_msg和on_msg_send是并发的，on_msg和on_msg、
on_msg_send和on_msg_send是顺序的；对于不同的st_tcp_socket（及其子类对象），on_msg和on_msg_send、on_msg和on_msg、on_msg_send
和on_msg_send都是并发的。
关于on_timer的并发性，不同st_timer之间当然是并发，同一个st_timer的同一个timer（以id区分timer）的on_timer是顺序，不同的timer
的on_timer是并发的。注意：多线程对同一个st_timer调用set_timer设置同一个timer（id相同），是不安全的，设计即是这样。
其它的方法，除了明显不应该设计为多线程的（比如初始化，开始结束服务等），都是线程安全的，比如send_msg等。

-------------------五------------------------
十五：高级应用
在3.5版本中，我增加了如下几个功能：
1. 添加了四个helper函数：safe_send_msg、safe_send_native_msg、safe_broadcast_msg和safe_broadcast_native_msg，
它能保证消息发送成功（成功仅仅是把消息放到sendbuffer里面），它们与用can_overflow为true调用send_msg、
send_native_msg、broadcast_msg和broadcast_native_msg的区别是，后者由于不考虑send buffer的大小限制，所以马上能成功，
而前者在send buffer满的时候，会阻塞等待，直到缓存可用，其实前者只是在出错（缓存满）的情况下，循环调用后者，所以并不是新东西。
2. 增加了在运行时暂停消息发送的功能，使用方法1是重写st_socket（它是st_tcp_socket和st_udp_socket的父类）的is_send_allowed虚函数，
返回flase表示暂停消息发送，这里的发送是指真实的发送（async_write），2是调用suspend_send_msg函数。这个功能最大的用处就是限制流量，
而且它是线程安全的，所以你可以在任何线程里面暂停和恢复消息发送。注意，当is_send_allowed返回假的时候，safe系列四个helper函数
不再保证发送成功，它的行为下降为与对应的非safe系统函数一样（普通情况下是sleep一小会儿之后，再次调用safe_send_msg或者
safe_send_native_msg直到成功，当你通过调用suspend_send_msg函数而暂停消息发送时，也会让is_send_allowed返回假，如果你没有重写
过is_send_allowed的话）。我的逻辑是，safe系列四个helper函数必须要把消息放入send buffer才能返回，如果is_send_allowed返回假，
那么如果send buffer已满，将没有机会回到send buffer不满的状态，因为消息发送已经暂停了，此时safe系列四个helper函数成了真正的
死循环；另外，如果io_service已经停止了，也会有同样的结果，原因同上。
3. 增加了在运行时暂停消息派发功能，不管使不使用recv buffer都有效，具体有什么用，请往下看。这里先说说他们的区别，如果使用recv 
buffer（这里专指定义了FORCE_TO_USE_MSG_RECV_BUFFER宏的情况，通过on_msg返回false来使用recvbuffer属于后者所说的情况），
则当暂停消息派发之后，消息会继续接收，直到recv buffer满，如果不使用recv buffer，则马上停止消息接收，直到消息派发重新被启用。
4. 为st_server_socket增加了模板支持，达到控制st_server_socket的成员变量server类型的目的，控制了server成员变量的类型，
可以实现在st_server_socket中调用st_server任意接口的目的（在on_recv_error中调用del_client就是这一类应用，二次开发者可做更多
的控制，在asio_server中有演示）。



