asio2----------------

#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

int num = 0;
void foo()
{
    std::cout << "hello " << ++num << std::endl;
}

int main(int argc, char* argv[])
{
    boost::asio::io_service ios;

    for (int i = 0; i < 10; ++i)
    {
        ios.post(foo);
    }

    std::cout << "执行run之前" << std::endl;
    ios.run();

    std::cout << "run执行完毕" << std::endl;

    return 0;
}
如果你想让完成一个事件返回一次，可续选择用run_one，这样的话只要完成一个事件就会返回一次，而不是所有的都完成了才返
回。使用run_one的话需要用配合stopped函数来判断是否所有时间都已经执行完了。其实run函数与下面的代码是一样的效果：

while(!ios.stopped())
{
	ios.run_one()
}

另外当所执行的事件出错时，run函数也会退出或抛出异常。run函数和run_one函数都有两个重载，没有参数的run或run_one在遇
到异常时自己也会会抛出boost::system::system_error异常，加了boost::system::error_code&参数的版本则会将错误信息写入
该参数然后返回。不过我还一直没遇到过run函数抛出异常或者出错的情况，可能是用的太少了。
既然只要还有“任务”，run就不会退出，个人认为一个好的设计应该一直让我们的发动机有事情可做，一直到做完所有的事情然后退出，如下面的代码：

#include <boost/bind.hpp>
#include <boost/asio.hpp>
#include <boost/filesystem.hpp>
#include <iostream>
void async_dir(boost::asio::io_service& io, boost::filesystem::directory_iterator& di)
{
    if (di == boost::filesystem::directory_iterator())
    {
        return;
    }

    if (boost::filesystem::is_directory(di->path()))
    {
        boost::system::error_code ec;
        boost::filesystem::directory_iterator sub_di(di->path(),ec);

        if (!ec)
        {
            io.post(boost::bind(&async_dir, boost::ref(io), sub_di));
        }
        else
        {
            std::cout << "遍历目录 " << di->path() << "出错，错误原因为：" << ec.message() << std::endl;
        }
    }

    std::cout << di->path() << std::endl;

    boost::system::error_code ec;
    ++di;
    io.post(boost::bind(&async_dir, boost::ref(io), di));
}

int main(int argc, char* argv[])
{
    boost::asio::io_service io;

    boost::filesystem::path p("C:\\");
    boost::system::error_code ec;
    boost::filesystem::directory_iterator di(p,ec);
    int num = 0;

    if (!ec)
    {
        io.post(boost::bind(&async_dir, boost::ref(io), di));
    }
    else
    {
        std::cout << "遍历目录 " << p << "出错，错误原因为：" << ec.message() << std::endl;
    }

    io.run();
    return 0;
}

异步递归：可由boost::asio::io_service中post,run,boost::Bind实现
这里就是在主函数中只post了一次，当函数完成或找到子文件夹时就再次调用post给发动机添加任务，直到所有的任务都已完成
，就无需添加任务了，run函数自然就退出了。
虽然最好的做法是一直让发动机有事可做而不会退出，可是有的时候可能并不能做的这么完善，但是又不想让run退出，这时候
你就需要boost::asio::io_service::work来帮忙，这个类的作用就是让io_service一直处于有事可做的状态而不会从run函数中
退出，这样就避免了我们自己写循环重复调用run函数。当work析构而且没有任务的时候，run就会返回，测试代码如下

#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

boost::asio::io_service::work* work = NULL;

void foo()
{
    std::cout << "hello" << std::endl;
}

void thd_fun()
{
    std::getchar();
    delete work;
}

int main(int argc, char* argv[])
{
    boost::asio::io_service ios;

    ios.post(foo);

    work = new boost::asio::io_service::work(ios);

    boost::thread thd(thd_fun);

    boost::system::error_code ec;

    std::cout << "before run" << std::endl;
    ios.run(ec);
    std::cout << "after run" << std::endl;

    return 0;
}

asio 3-----------------------------------------------
asio支持同步和异步的网络操作，而且可以混用。可能有人会吐槽我之前为啥只写异步的东西，因为同步的话其实就只直接调用函数..
那样的话跟asio一点关系都没有了我还写啥。不过网络方面的函数到时可以一写，不过这样就是放弃了asio的异步功能。
对于异步和同步的优缺点，其实我自己也说不太清楚，毕竟也是刚接触异步不久，也不好乱说，所以目前就只管学会怎么用，但是
大多数人都是对同步的操作比较熟悉，所以这里还是先写一下asio进行同步的网络操作的方法。

#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

void session(boost::asio::ip::tcp::socket* sock)
{
    std::cout << "有客户端连接" << std::endl;

    char data[1024];

    for (;;)
    {
        boost::system::error_code error;
        size_t length = sock->read_some(boost::asio::buffer(data), error);
        if (error == boost::asio::error::eof)
            break; // Connection closed cleanly by peer.
        else if (error)
        {
            std::cout << "read_some发生错误：" << error.message() << std::endl; // Some other error.
            break;
        }

        boost::asio::write(*sock, boost::asio::buffer(data, length),error);
        if (error)
        {
            std::cout << "write发生错误：" << error.message() << std::endl;
            break;
        }
    }

    delete sock;

    std::cout << "完事走掉了" << std::endl;
}

int main(int argc, char* argv[])
{
    boost::asio::io_service ios;
    boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(),1234);

    boost::asio::ip::tcp::acceptor acceptor(ios, endpoint);

    for (;;)
    {
        boost::asio::ip::tcp::socket* sock = new boost::asio::ip::tcp::socket(ios);
        acceptor.accept(*sock);

        boost::thread(&session, sock).detach();
    }

    return 0;
}

boost::asio::io_service ios;这个大家都知道是啥了，但是还是得说一下，虽然在同步的程序里面这玩意意义不大，但是还是必须要有的，如果
你确定io_service里面没有要执行的异步任务，可以不用调用ios.run()，即使是调用了也会立即返回，如果不确定的话还是调用一下ios.stopped()
确认一下或者直接调用一下run函数确定的吧一步任务也都做完。
boost::asio::ip::tcp::endpoint表示一个tcp的endpoint（我不知道这个endpoint该怎么翻译好..）。asio中用一个endpoint来表示一个节点，因
为asio不只是支持一种协议，每种协议都有个endpoint来表示一个节点，tpc协议的一个节点的标识就是IP地址和端口号，有了IP地址和端口号就能
找到这个节点，所以endpoint的初始化需要一个IP地址和一个端口号。这里因为要监听本地网卡上的所有的IP地址，所以就用了
boost::asio::ip::tcp::v4()
后面的1234自然就是端口号了。如果你想从一个字符串转换成endpoint也可以这么写：
boost::asio::ip::tcp::endpoint ep(boost::asio::ip::address::from_string(std::string("127.0.0.1")), 1234);
boost::asio::ip::address::from_string()函数可以从字符串里面解析得到一个IP地址，他可以自动检测你输入的字符串是IPv4还是v6的。如果自
己确定是v4还是v6，可以明确地用boost::asio::ip::address_v4::from_string()或者boost::asio::ip::address_6::from_string()。
有了endpoint了，我们就可以继续往下搞了，如果这个endpoint是我们自己，我们可以在这个endpoint上进行监听，等待别人来进行连接，如果是一个远程的endpoint，
我们可以连接这个endpoint（不过好像asio中很少用endpoint来进行连接，用什么等后面写连接的client的时候说）。这里我们是要做server，肯定就是要在这个endpoint上
进行监听。
asio把原来的socket的bind、listen、accept之类的操作都封装成了一个类boost::asio::ip::tcp::acceptor，把io_service 和endpoint传给他创建一个acceptor，
然后调用accept成员函数就可以等待客户端的连接了。accept函数需要一个boost::asio::ip::tcp::socket，这个就是与该客户端连接的socket句柄，后续与该客户端的通讯都需要他
。因为这个类不准拷贝，为了防止他析构只能new出来了，在不用的时候自己delete。
接到一个客户端的连接就开一个线程与他通信，主线程继续accept，同步网络通讯的典型做法，不废话了，看session函数里面的操作。
也很简单，从客户端那里读取数据，然后原封不动的写回去。这里要注意下read_some和read的区别，
read_some是读取到一段数据就返回，不管读取的大小是否已经达到用户提供的缓冲区大小，什么时候返回跟tcp协议和操作系统的实现有关，这点我也不太了解，就不乱说了；
read则是一直读取直到读取到用户指定的大小然后才返回，没有读取完是不会返回的；
相同原理的还有write_some和write。
不过我有一点不太理解的是read_some和write_some是boost::asio::ip::tcp::socket的成员函数，而read和write则是boost::asio命名空间下的独立的函数.

asio4------------------------
同步的发起连接和发送数据的相关的函数

#include <boost/asio.hpp>
#include <iostream>
#include <string>

int main(int argc, char* argv[])
{
    boost::asio::io_service io_service;

    boost::asio::ip::tcp::resolver resolver(io_service);
    boost::asio::ip::tcp::resolver::query query(boost::asio::ip::tcp::v4(), "127.0.0.1", "1234");
    boost::asio::ip::tcp::resolver::iterator iterator = resolver.resolve(query);

    boost::asio::ip::tcp::socket sock(io_service);
    boost::asio::connect(sock, iterator);

    for (;;)
    {
        std::string line;
        getline(std::cin, line);

        boost::asio::write(sock, boost::asio::buffer(line.c_str(), line.size()+1));

        char reply[1024];

        boost::asio::read(sock, boost::asio::buffer(reply, line.size() + 1));

        std::cout << reply << std::endl;
    }

    return 0;
}
这里的boost::asio::ip::tcp::resolver就是前一篇文章说的其他的创建endpoint进行连接的方法，要说这个resolver跟跟直接创建endpoint的区别，
个人感觉是resolver更方便一些，不但能解析IP地址的字符串，还能根据服务名解析出相应的端口，并且有的函数的参数只能是resolve返回的iterator。
其实这个类就是对getaddrinfo这个socket函数的一个封装，想要详细了解的童鞋可以去看看unix网络编程。resolve返回的是一个iterator，
原因是写的是主机名的话可能返回的IP地址不止一个，但是绝大多数时候我们都是写的IP地址，所以只取第一个iterator就行了；iterator->endpoint()
则可以方便的获取这个iterator对应的endpoint。
有了endpoint之后，我们就可以连接这个endpoint了，connect是一个单独的函数，可能是因为功能比较单一就没有封装成类。boost::asio::connect需要的
是一个resolver返回的iterator而不是一个endpoint，这点我也比较奇怪；然后是一个boost::asio::ip::tcp::socket，连接成功后这个就是连接的socket句柄。

asio5 -------------------------------
前面也说过，asio的异步网络函数和同步的差别不大，只是异步和同步的思想的差别。如果前面的同步的函数都搞懂了，那只需要转换一下思维方式就可以了
——把要做的事提交给io_service，在run中执行他们，在事件完成的通知中进行下一步的操作

// asio_sample.cpp : 定义控制台应用程序的入口点。
//

#include <boost/asio.hpp>
#include <boost/bind.hpp>
#include <iostream>

boost::asio::io_service ios;
boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(), 1234);
boost::asio::ip::tcp::acceptor acceptor(ios, endpoint);

char data[1024];

void handle_read(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred);

void handle_write(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred)
{
    if (error)
    {
        std::cout << "write发生错误：" << error.message() << std::endl;
        delete sock;
        return;
    }

    sock->async_read_some(boost::asio::buffer(data),
        boost::bind(handle_read, sock,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
}

void handle_read(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred)
{
    if (error)
    {
        std::cout << "read发生错误：" << error.message() << std::endl;
        delete sock;
        return;
    }

    boost::asio::async_write(*sock, boost::asio::buffer(data, bytes_transferred),
        boost::bind(handle_write, sock,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
}

void session(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error)
{
    if (error)
    {
        delete sock;
    }
    else
    {
        std::cout << "有客户端连接" << std::endl;

        sock->async_read_some(boost::asio::buffer(data),
            boost::bind(handle_read, sock,
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s,
        boost::asio::placeholders::error));
}

int main(int argc, char* argv[])
{
    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s, boost::asio::placeholders::error));

    ios.run();
    return 0;
}
跟同步的那个echo server是一样的东西功能，就不截图了。而且为了容易看清条理实现的比较丑陋。可以看出来这里并没有使用线程，却实现了跟同步多线程的
echo server相同的功能——可以同时跟多个客户端通信。下面就详细解释一下代码。
为了使用方便我把boost::asio::io_service、boost::asio::ip::tcp::endpoint和boost::asio::ip::tcp::acceptor定义成了全局变量，这三个类的使用和同步程序中
的一模一样就不多说了。下面依然是每个boost::asio::ip::tcp::socket代表收到的一个请求，不同的是这次没有开新的线程，而是直接在async_accept的handler
（也就是session函数）中进行的处理，在session函数中，我们先发了一个异步读取数据的“任务”
（sock->async_read_some）给io_service，然后又发了一个异步接收请求的“任务”（acceptor.async_accept）给io_service，
因为只是发任务，函数式立即返回的，因此我们可以认为这两个任务在同时进行。发读取数据的任务是为了接受客户端发来的数据，发accept任务是为了等待其他的客户端的连接。
在同步的程序中，不开多个线程是不可能做到的，因为我们如果先执行read任务的话，而客户端一直不发送数据，我们会一直阻塞在read函数里面；accept也是同样的道理。
发了这两个任务之后，我们就进入了两个“循环”中，不明白这两个循环怎么来的请仔细看这里，一个循环一直等待客户的连接，另一个循环则重复执行着
读取数据->返回给客户端->继续读取->返回给客户端....直到客户端下线或者其他错误发生时，就不再发异步任务，循环也就停止了。这样就实现了一个线程，多个循环。

应该很容易就能看出其实异步的网络函数和同步的差别不大，不过是多了个完成后的回调，结果都在回调中得知。你的回调需要哪方面的结果，
就bind上boost::asio::placeholders命名空间下的对应的项。其中比较常用的是boost::asio::placeholders::error和boost::asio::placeholders::bytes_transferred，
分别表示异步事件执行是否出错以及传送的数据的字节数。其他的项我也没用过，以后用到再说。

/异步读取完成的handler
void handle_read(boost::asio::ip::tcp::socket* sock,size_t size,
    const boost::system::error_code& error,
    size_t bytes_transferred);

......
//某个函数中
    size_t size = 0;
    boost::asio::async_read(*sock,boost::asio::buffer(&size,sizeof(size)),
        boost::bind(handle_read,sock,size,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
.......

这段代码有两个严重的错误：
1.要确定异步读取的目标缓冲区的存活时间不能比事件的完成时间短，不管是异步读取还是异步写入。因为事件完成几乎总是在发起异步事件的函数（调用
 async_read或async_write的函数）完成之后才会触发，这时候上面代码中的size已经析构了，异步读取或写入会写入到一个不存在的 
 buffer中，局部变量是放在栈上，这时这个变量的位置可能已经变成了另一个变量了，这肯定不是我们想要的结果。
2.不要把异步读取写入的目标bind到读取完成的handler上。因为bind实际上是吧size的值（0）保存了下来，所以，不管读取到的实际大小是多少，
handler中始终会得到大小为0；
3.还有一个坑，就不写代码了。在同一个socket句柄上，不可以同时有多于一个异步读取或异步写入事件，必须等一个完成才能发下一个。
原因很简单，一起读的话来了数据算谁的？一起写的话数据都写混乱了。

asio7---------------------------------
基于asio echo server 改写 ,使用智能指针

#include <cstdlib>
#include <iostream>
#include <boost/bind.hpp>
#include <boost/asio.hpp>
#include <boost/smart_ptr.hpp>

using boost::asio::ip::tcp;

class session : public boost::enable_shared_from_this<session>
{
public:

    typedef boost::shared_ptr<session> session_ptr;

    static session_ptr get_new_session(boost::asio::io_service& io_service)
    {
        return session_ptr(new session(io_service));
    }
    tcp::socket& socket()
    {
        return socket_;
    }

    ~session()
    {
        std::cout << "析构" << std::endl;
    }

    void start()
    {
        socket_.async_read_some(boost::asio::buffer(data_, max_length),
            boost::bind(&session::handle_read, shared_from_this(),
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

private:
    session(boost::asio::io_service& io_service)
        : socket_(io_service)
    {
    }

    void handle_read(const boost::system::error_code& error,
        size_t bytes_transferred)
    {
        if (!error)
        {
            boost::asio::async_write(socket_,
                boost::asio::buffer(data_, bytes_transferred),
                boost::bind(&session::handle_write, shared_from_this(),
                boost::asio::placeholders::error));
        }
    }

    void handle_write(const boost::system::error_code& error)
    {
        if (!error)
        {
            socket_.async_read_some(boost::asio::buffer(data_, max_length),
                boost::bind(&session::handle_read, shared_from_this(),
                boost::asio::placeholders::error,
                boost::asio::placeholders::bytes_transferred));
        }
    }

    tcp::socket socket_;
    enum { max_length = 1024 };
    char data_[max_length];
};

class server
{
public:
    server(boost::asio::io_service& io_service, short port)
        : io_service_(io_service),
        acceptor_(io_service, tcp::endpoint(tcp::v4(), port))
    {
        start_accept();
    }

private:
    void start_accept()
    {
        session::session_ptr new_session = session::get_new_session(io_service_);
        acceptor_.async_accept(new_session->socket(),
            boost::bind(&server::handle_accept, this, new_session,
            boost::asio::placeholders::error));
    }

    void handle_accept(session::session_ptr new_session,
        const boost::system::error_code& error)
    {
        if (!error)
        {
            new_session->start();
        }

        start_accept();
    }

    boost::asio::io_service& io_service_;
    tcp::acceptor acceptor_;
};

int main(int argc, char* argv[])
{
    try
    {
        if (argc != 2)
        {
            std::cerr << "Usage: async_tcp_echo_server <port>\n";
            return 1;
        }

        boost::asio::io_service io_service;

        using namespace std; // For atoi.
        server s(io_service, atoi(argv[1]));

        io_service.run();
    }
    catch (std::exception& e)
    {
        std::cerr << "Exception: " << e.what() << "\n";
    }

    return 0;
}
代码很简单，一个server类，里面循环accept新的客户端的连接，收到之后创建一个新的session类，session类中循环async_read
 、async_write，与asio原示例不同之处仅仅是把里面所有的delete this去掉了。因为使用了shared_ptr和enable_shared_from_this，
 只要async_read 、async_write的循环没有终止，则必定会有某个bind持有一个session的shared_ptr，保存在bind返回的function里面，
 只要我们在这个function结束之前再次发起一个异步任务并把session的shared_ptr给bind上去，这个指针的引用计数就不会变为0，也就不会析构；
 如果出错，我们就不再继续发起任务，等函数结束时，引用计数就会自动变为0，shared_ptr会自动帮你delete掉这个对象。
另外这里吧session的构造函数设置成私有的并且用了一个静态函数进行构建，是为了防止有人直接在栈上实例化了session类，这样做没啥意义，
也可以减少new的出现（虽然我不知道减少new出现有啥好处）。

asio 8 --------------------------------------------------



