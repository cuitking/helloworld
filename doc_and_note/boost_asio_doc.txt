asio 学习笔记论坛地址：http://godebug.org/index.php/archives/56/

一般来说大多数人使用asio都是用它来做异步的网络库来使用,但是asio本质上是一个通用的异步库，
并不是只能用来做网络通信，
异步的概念其实很简单，你把要做的事情告诉可以完成这件事的库或者操作系统，由库或操作系统帮你
完成并通知你，在此期间你可以做其他的操作。
asio异步的核心其实就是一个boost::asio::io_service类，可以想象成一个发动机，你有事情要做，就
扔给他，他就帮你完成，你把事情告诉他之后并不需要一直等待事情的完成，而是可以马上去做其他的事情，
其中类的成员函数post()就是提交要做的事情，成员函数run()就是启动发动机.

#include <boost/asio.hpp>
#include <iostream>

void testfoo()
{
	std::cout << " hello testfoo !!!!" << std::endl;

}

int main(int argc, char** argv)
{
	boost::asio::io_service ios;
	ios.post(testfoo);
	std::cout << " after ios post!!!!" << std::endl;
	ios.run();
	system("pause");
	return 0;
}
输出：
 after ios post!!!!!
 hello testfoo !!!!!
 可以看到提交“任务”之后并没有马上执行，而是等到了run的时候才开始执行的。看起来很简单是吧，
 假设foo函数式是系统提供的，但是提供了个回调函数在完成后会进行调用来通知我们。

 #include <boost/asio.hpp>
 #include <boost/bind/bind.hpp>
 #include <iostream>
 #include <functional>

 typedef std::function<void()> handler_t;
 void foo(handler_t handler)
 {
 	std::cout << "hello asio foo" << std::endl;

 	handler();
 }

 void handler_fun()
 {
 	std::cout << " mission complete!!!!" << std::endl;
 }

 int main(int argc, char ** argv)
 {
 	boost::asio::io_service ios;
 	ios.post(boost::bind(foo, handler_fun));

 	std::cout << "after post" << std::endl;
 	ios.run();
 	return 0;
 }

 其实asio的网络操作函数也与此类似,foo是执行指定任务的函数，执行完成后就调用我们的handler来通知
 我们，这样我们就可以不用一直等待操作完成，立即去执行其他的任务。
 这样做还有一个优点是可以在多个线程上执行run函数，可以更充分利用多核的性能，“任务”并不是在
 提交任务的线程中执行的，而是在执行run的线程中执行的，如果多个线程同时执行同一个io_service对象
 的run函数，则会每个线程都去从这个service的“任务列表”里面获取任务去执行.

#include <boost/asio.hpp>
#include <boost/bind/bind.hpp>
#include <boost/thread.hpp>
#include <iostream>

void foo()
{
	std::cout << "hello asio , thread ID : " << boost::this_thread:get_id() << std::endl;
}

int main(int argc, char ** argv)
{
	boost::asio::io_service ios;

	for (int i = 0; i < 1000; ++i)
	{
		ios.post(foo);
	}

	boost::thread_group threads;
	for (int i = 0; i < 4; ++i)
	{
		threads.create_thread(boost::bind(&boost::asio::io_service::run, &ios));
	}
	threads.join_all();
	return 0;
}

asio 2--------------------------------
io_service::run函数什么时候会退出
#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

int num = 0;
void foo()
{
	std::cout << "hello " << ++num << std::endl;
}

int main(int argc, char* argv[])
{
	boost::asio::io_service ios;

	for (int i = 0; i < 10; ++i)
	{
		ios.post(foo);
	}

	std::cout << " excute run function before!!!!" << std::endl;
	ios.run();
	std::cout <<　" run function has finished !!!!!" << std::endl;
	return 0;
}
如果你想让完成一个事件返回一次，可续选择用run_one，这样的话只要完成一个事件就会返回一次，而不是所有的都完成了才返
回。使用run_one的话需要用配合stopped函数来判断是否所有时间都已经执行完了。其实run函数与下面的代码是一样的效果：

while(!ios.stopped())
{
	ios.run_one()
}

另外当所执行的事件出错时，run函数也会退出或抛出异常。run函数和run_one函数都有两个重载，没有参数的run或run_one在遇
到异常时自己也会会抛出boost::system::system_error异常，加了boost::system::error_code&参数的版本则会将错误信息写入
该参数然后返回。不过我还一直没遇到过run函数抛出异常或者出错的情况，可能是用的太少了。
既然只要还有“任务”，run就不会退出，个人认为一个好的设计应该一直让我们的发动机有事情可做，一直到做完所有的事情然后退出，如下面的代码：

#include <boost/bind.hpp>
#include <boost/asio.hpp>
#include <boost/filesystem.hpp>
#include <iostream>
void async_dir(boost::asio::io_service& io, boost::filesystem::directory_iterator& di)
{
    if (di == boost::filesystem::directory_iterator())
    {
        return;
    }

    if (boost::filesystem::is_directory(di->path()))
    {
        boost::system::error_code ec;
        boost::filesystem::directory_iterator sub_di(di->path(),ec);

        if (!ec)
        {
            io.post(boost::bind(&async_dir, boost::ref(io), sub_di));
        }
        else
        {
            std::cout << "遍历目录 " << di->path() << "出错，错误原因为：" << ec.message() << std::endl;
        }
    }

    std::cout << di->path() << std::endl;

    boost::system::error_code ec;
    ++di;
    io.post(boost::bind(&async_dir, boost::ref(io), di));
}

int main(int argc, char* argv[])
{
    boost::asio::io_service io;

    boost::filesystem::path p("C:\\");
    boost::system::error_code ec;
    boost::filesystem::directory_iterator di(p,ec);
    int num = 0;

    if (!ec)
    {
        io.post(boost::bind(&async_dir, boost::ref(io), di));
    }
    else
    {
        std::cout << "遍历目录 " << p << "出错，错误原因为：" << ec.message() << std::endl;
    }

    io.run();
    return 0;
}

异步递归：可由boost::asio::io_service中post,run,boost::Bind实现
这里就是在主函数中只post了一次，当函数完成或找到子文件夹时就再次调用post给发动机添加任务，直到所有的任务都已完成
，就无需添加任务了，run函数自然就退出了。
虽然最好的做法是一直让发动机有事可做而不会退出，可是有的时候可能并不能做的这么完善，但是又不想让run退出，这时候
你就需要boost::asio::io_service::work来帮忙，这个类的作用就是让io_service一直处于有事可做的状态而不会从run函数中
退出，这样就避免了我们自己写循环重复调用run函数。当work析构而且没有任务的时候，run就会返回，测试代码如下

#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

boost::asio::io_service::work* work = NULL;

void foo()
{
    std::cout << "hello" << std::endl;
}

void thd_fun()
{
    std::getchar();
    delete work;
}

int main(int argc, char* argv[])
{
    boost::asio::io_service ios;

    ios.post(foo);

    work = new boost::asio::io_service::work(ios);

    boost::thread thd(thd_fun);

    boost::system::error_code ec;

	std::cout << " excute run function before!!!!" << std::endl;
    ios.run(ec);
    std::cout << "after run" << std::endl;

    return 0;
}

asio 3-----------------------------------------------
asio支持同步和异步的网络操作，而且可以混用。可能有人会吐槽我之前为啥只写异步的东西，因为同步的话其实就只直接调用函数..
那样的话跟asio一点关系都没有了我还写啥。不过网络方面的函数到时可以一写，不过这样就是放弃了asio的异步功能。
对于异步和同步的优缺点，其实我自己也说不太清楚，毕竟也是刚接触异步不久，也不好乱说，所以目前就只管学会怎么用，但是
大多数人都是对同步的操作比较熟悉，所以这里还是先写一下asio进行同步的网络操作的方法。

#include <boost/asio.hpp>
#include <boost/thread.hpp>
#include <iostream>

void session(boost::asio::ip::tcp::socket* sock)
{
    std::cout << "有客户端连接" << std::endl;

    char data[1024];

    for (;;)
    {
        boost::system::error_code error;
        size_t length = sock->read_some(boost::asio::buffer(data), error);
        if (error == boost::asio::error::eof)
            break; // Connection closed cleanly by peer.
        else if (error)
        {
            std::cout << "read_some发生错误：" << error.message() << std::endl; // Some other error.
            break;
        }

        boost::asio::write(*sock, boost::asio::buffer(data, length),error);
        if (error)
        {
            std::cout << "write发生错误：" << error.message() << std::endl;
            break;
        }
    }

    delete sock;

    std::cout << "完事走掉了" << std::endl;
}

int main(int argc, char* argv[])
{
    boost::asio::io_service ios;
    boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(),1234);

    boost::asio::ip::tcp::acceptor acceptor(ios, endpoint);

    for (;;)
    {
        boost::asio::ip::tcp::socket* sock = new boost::asio::ip::tcp::socket(ios);
        acceptor.accept(*sock);

        boost::thread(&session, sock).detach();
    }

    return 0;
}

boost::asio::io_service ios;这个大家都知道是啥了，但是还是得说一下，虽然在同步的程序里面这玩意意义不大，但是还是必须要有的，如果
你确定io_service里面没有要执行的异步任务，可以不用调用ios.run()，即使是调用了也会立即返回，如果不确定的话还是调用一下ios.stopped()
确认一下或者直接调用一下run函数确定的吧一步任务也都做完。
boost::asio::ip::tcp::endpoint表示一个tcp的endpoint（我不知道这个endpoint该怎么翻译好..）。asio中用一个endpoint来表示一个节点，因
为asio不只是支持一种协议，每种协议都有个endpoint来表示一个节点，tpc协议的一个节点的标识就是IP地址和端口号，有了IP地址和端口号就能
找到这个节点，所以endpoint的初始化需要一个IP地址和一个端口号。这里因为要监听本地网卡上的所有的IP地址，所以就用了
boost::asio::ip::tcp::v4()
后面的1234自然就是端口号了。如果你想从一个字符串转换成endpoint也可以这么写：
boost::asio::ip::tcp::endpoint ep(boost::asio::ip::address::from_string(std::string("127.0.0.1")), 1234);
boost::asio::ip::address::from_string()函数可以从字符串里面解析得到一个IP地址，他可以自动检测你输入的字符串是IPv4还是v6的。如果自
己确定是v4还是v6，可以明确地用boost::asio::ip::address_v4::from_string()或者boost::asio::ip::address_6::from_string()。
有了endpoint了，我们就可以继续往下搞了，如果这个endpoint是我们自己，我们可以在这个endpoint上进行监听，等待别人来进行连接，如果是一个远程的endpoint，
我们可以连接这个endpoint（不过好像asio中很少用endpoint来进行连接，用什么等后面写连接的client的时候说）。这里我们是要做server，肯定就是要在这个endpoint上
进行监听。
asio把原来的socket的bind、listen、accept之类的操作都封装成了一个类boost::asio::ip::tcp::acceptor，把io_service 和endpoint传给他创建一个acceptor，
然后调用accept成员函数就可以等待客户端的连接了。accept函数需要一个boost::asio::ip::tcp::socket，这个就是与该客户端连接的socket句柄，后续与该客户端的通讯都需要他
。因为这个类不准拷贝，为了防止他析构只能new出来了，在不用的时候自己delete。
接到一个客户端的连接就开一个线程与他通信，主线程继续accept，同步网络通讯的典型做法，不废话了，看session函数里面的操作。
也很简单，从客户端那里读取数据，然后原封不动的写回去。这里要注意下read_some和read的区别，
read_some是读取到一段数据就返回，不管读取的大小是否已经达到用户提供的缓冲区大小，什么时候返回跟tcp协议和操作系统的实现有关，这点我也不太了解，就不乱说了；
read则是一直读取直到读取到用户指定的大小然后才返回，没有读取完是不会返回的；
相同原理的还有write_some和write。
不过我有一点不太理解的是read_some和write_some是boost::asio::ip::tcp::socket的成员函数，而read和write则是boost::asio命名空间下的独立的函数.

asio4------------------------
同步的发起连接和发送数据的相关的函数

#include <boost/asio.hpp>
#include <iostream>
#include <string>

int main(int argc, char* argv[])
{
    boost::asio::io_service io_service;

    boost::asio::ip::tcp::resolver resolver(io_service);
    boost::asio::ip::tcp::resolver::query query(boost::asio::ip::tcp::v4(), "127.0.0.1", "1234");
    boost::asio::ip::tcp::resolver::iterator iterator = resolver.resolve(query);

    boost::asio::ip::tcp::socket sock(io_service);
    boost::asio::connect(sock, iterator);

    for (;;)
    {
        std::string line;
        getline(std::cin, line);

        boost::asio::write(sock, boost::asio::buffer(line.c_str(), line.size()+1));

        char reply[1024];

        boost::asio::read(sock, boost::asio::buffer(reply, line.size() + 1));

        std::cout << reply << std::endl;
    }

    return 0;
}
这里的boost::asio::ip::tcp::resolver就是前一篇文章说的其他的创建endpoint进行连接的方法，要说这个resolver跟跟直接创建endpoint的区别，
个人感觉是resolver更方便一些，不但能解析IP地址的字符串，还能根据服务名解析出相应的端口，并且有的函数的参数只能是resolve返回的iterator。
其实这个类就是对getaddrinfo这个socket函数的一个封装，想要详细了解的童鞋可以去看看unix网络编程。resolve返回的是一个iterator，
原因是写的是主机名的话可能返回的IP地址不止一个，但是绝大多数时候我们都是写的IP地址，所以只取第一个iterator就行了；iterator->endpoint()
则可以方便的获取这个iterator对应的endpoint。
有了endpoint之后，我们就可以连接这个endpoint了，connect是一个单独的函数，可能是因为功能比较单一就没有封装成类。boost::asio::connect需要的
是一个resolver返回的iterator而不是一个endpoint，这点我也比较奇怪；然后是一个boost::asio::ip::tcp::socket，连接成功后这个就是连接的socket句柄。

asio5 -------------------------------
前面也说过，asio的异步网络函数和同步的差别不大，只是异步和同步的思想的差别。如果前面的同步的函数都搞懂了，那只需要转换一下思维方式就可以了
——把要做的事提交给io_service，在run中执行他们，在事件完成的通知中进行下一步的操作

// asio_sample.cpp : 定义控制台应用程序的入口点。
//

#include <boost/asio.hpp>
#include <boost/bind.hpp>
#include <iostream>

boost::asio::io_service ios;
boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(), 1234);
boost::asio::ip::tcp::acceptor acceptor(ios, endpoint);

char data[1024];

void handle_read(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred);

void handle_write(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred)
{
    if (error)
    {
        std::cout << "write发生错误：" << error.message() << std::endl;
        delete sock;
        return;
    }

    sock->async_read_some(boost::asio::buffer(data),
        boost::bind(handle_read, sock,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
}

void handle_read(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,
    size_t bytes_transferred)
{
    if (error)
    {
        std::cout << "read发生错误：" << error.message() << std::endl;
        delete sock;
        return;
    }

    boost::asio::async_write(*sock, boost::asio::buffer(data, bytes_transferred),
        boost::bind(handle_write, sock,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
}

void session(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error)
{
    if (error)
    {
        delete sock;
    }
    else
    {
        std::cout << "有客户端连接" << std::endl;

        sock->async_read_some(boost::asio::buffer(data),
            boost::bind(handle_read, sock,
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s,
        boost::asio::placeholders::error));
}

int main(int argc, char* argv[])
{
    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s, boost::asio::placeholders::error));

    return 0;
}
跟同步的那个echo server是一样的东西功能，就不截图了。而且为了容易看清条理实现的比较丑陋。可以看出来这里并没有使用线程，却实现了跟同步多线程的
echo server相同的功能——可以同时跟多个客户端通信。下面就详细解释一下代码。
为了使用方便我把boost::asio::io_service、boost::asio::ip::tcp::endpoint和boost::asio::ip::tcp::acceptor定义成了全局变量，这三个类的使用和同步程序中
的一模一样就不多说了。下面依然是每个boost::asio::ip::tcp::socket代表收到的一个请求，不同的是这次没有开新的线程，而是直接在async_accept的handler
（也就是session函数）中进行的处理，在session函数中，我们先发了一个异步读取数据的“任务”
（sock->async_read_some）给io_service，然后又发了一个异步接收请求的“任务”（acceptor.async_accept）给io_service，
因为只是发任务，函数式立即返回的，因此我们可以认为这两个任务在同时进行。发读取数据的任务是为了接受客户端发来的数据，发accept任务是为了等待其他的客户端的连接。
在同步的程序中，不开多个线程是不可能做到的，因为我们如果先执行read任务的话，而客户端一直不发送数据，我们会一直阻塞在read函数里面；accept也是同样的道理。
发了这两个任务之后，我们就进入了两个“循环”中，不明白这两个循环怎么来的请仔细看这里，一个循环一直等待客户的连接，另一个循环则重复执行着
读取数据->返回给客户端->继续读取->返回给客户端....直到客户端下线或者其他错误发生时，就不再发异步任务，循环也就停止了。这样就实现了一个线程，多个循环。
应该很容易就能看出其实异步的网络函数和同步的差别不大，不过是多了个完成后的回调，结果都在回调中得知。你的回调需要哪方面的结果，
就bind上boost::asio::placeholders命名空间下的对应的项。其中比较常用的是boost::asio::placeholders::error和boost::asio::placeholders::bytes_transferred，
分别表示异步事件执行是否出错以及传送的数据的字节数。其他的项我也没用过，以后用到再说。

/异步读取完成的handler
void handle_read(boost::asio::ip::tcp::socket* sock,size_t size,
    const boost::system::error_code& error,
    size_t bytes_transferred);

......
//某个函数中
    size_t size = 0;
    boost::asio::async_read(*sock,boost::asio::buffer(&size,sizeof(size)),
        boost::bind(handle_read,sock,size,
        boost::asio::placeholders::error,
        boost::asio::placeholders::bytes_transferred));
.......

这段代码有两个严重的错误：
1.要确定异步读取的目标缓冲区的存活时间不能比事件的完成时间短，不管是异步读取还是异步写入。因为事件完成几乎总是在发起异步事件的函数（调用
 async_read或async_write的函数）完成之后才会触发，这时候上面代码中的size已经析构了，异步读取或写入会写入到一个不存在的 
 buffer中，局部变量是放在栈上，这时这个变量的位置可能已经变成了另一个变量了，这肯定不是我们想要的结果。
2.不要把异步读取写入的目标bind到读取完成的handler上。因为bind实际上是吧size的值（0）保存了下来，所以，不管读取到的实际大小是多少，
handler中始终会得到大小为0；
3.还有一个坑，就不写代码了。在同一个socket句柄上，不可以同时有多于一个异步读取或异步写入事件，必须等一个完成才能发下一个。
原因很简单，一起读的话来了数据算谁的？一起写的话数据都写混乱了。

asio6---------------------------------
基于asio echo server 改写 ,使用智能指针

#include <cstdlib>
#include <iostream>
#include <boost/bind.hpp>
#include <boost/asio.hpp>
#include <boost/smart_ptr.hpp>

using boost::asio::ip::tcp;

class session : public boost::enable_shared_from_this<session>
{
public:

    typedef boost::shared_ptr<session> session_ptr;

    static session_ptr get_new_session(boost::asio::io_service& io_service)
    {
        return session_ptr(new session(io_service));
    }
    tcp::socket& socket()
    {
        return socket_;
    }

    ~session()
    {
        std::cout << "析构" << std::endl;
    }

    void start()
    {
        socket_.async_read_some(boost::asio::buffer(data_, max_length),
            boost::bind(&session::handle_read, shared_from_this(),
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

private:
    session(boost::asio::io_service& io_service)
        : socket_(io_service)
    {
    }

    void handle_read(const boost::system::error_code& error,
        size_t bytes_transferred)
    {
        if (!error)
        {
            boost::asio::async_write(socket_,
                boost::asio::buffer(data_, bytes_transferred),
                boost::bind(&session::handle_write, shared_from_this(),
                boost::asio::placeholders::error));
        }
    }

    void handle_write(const boost::system::error_code& error)
    {
        if (!error)
        {
            socket_.async_read_some(boost::asio::buffer(data_, max_length),
                boost::bind(&session::handle_read, shared_from_this(),
                boost::asio::placeholders::error,
                boost::asio::placeholders::bytes_transferred));
        }
    }

    tcp::socket socket_;
    enum { max_length = 1024 };
    char data_[max_length];
};

class server
{
public:
    server(boost::asio::io_service& io_service, short port)
        : io_service_(io_service),
        acceptor_(io_service, tcp::endpoint(tcp::v4(), port))
    {
        start_accept();
    }

private:
    void start_accept()
    {
        session::session_ptr new_session = session::get_new_session(io_service_);
        acceptor_.async_accept(new_session->socket(),
            boost::bind(&server::handle_accept, this, new_session,
            boost::asio::placeholders::error));
    }

    void handle_accept(session::session_ptr new_session,
        const boost::system::error_code& error)
    {
        if (!error)
        {
            new_session->start();
        }

        start_accept();
    }

    boost::asio::io_service& io_service_;
    tcp::acceptor acceptor_;
};

int main(int argc, char* argv[])
{
    try
    {
        if (argc != 2)
        {
            std::cerr << "Usage: async_tcp_echo_server <port>\n";
            return 1;
        }

        boost::asio::io_service io_service;

        using namespace std; // For atoi.
        server s(io_service, atoi(argv[1]));

        io_service.run();
    }
    catch (std::exception& e)
    {
        std::cerr << "Exception: " << e.what() << "\n";
    }

代码很简单，一个server类，里面循环accept新的客户端的连接，收到之后创建一个新的session类，session类中循环async_read
 、async_write，与asio原示例不同之处仅仅是把里面所有的delete this去掉了。因为使用了shared_ptr和enable_shared_from_this，
 只要async_read 、async_write的循环没有终止，则必定会有某个bind持有一个session的shared_ptr，保存在bind返回的function里面，
 只要我们在这个function结束之前再次发起一个异步任务并把session的shared_ptr给bind上去，这个指针的引用计数就不会变为0，也就不会析构；
 如果出错，我们就不再继续发起任务，等函数结束时，引用计数就会自动变为0，shared_ptr会自动帮你delete掉这个对象。
另外这里吧session的构造函数设置成私有的并且用了一个静态函数进行构建，是为了防止有人直接在栈上实例化了session类，这样做没啥意义，
也可以减少new的出现（虽然我不知道减少new出现有啥好处）。
asio 7 --------------------------------------------------

asio中用到了两种coroutine，一个是asio作者自己写的stackless coroutine，一个是封装了Boost.Coroutine的spawn，
Boost.Coroutine是boost库中的一个stackful coroutine。其实这两个的主要区别我觉得就是stackless的不能使用局部变量，但是速度较快；
stackful的可以使用局部变量，但是速度可能不如stackless的。
首先说一下coroutine是个什么玩意，其实很多语言中都有这个东西，个人感觉这个玩意就像hyq童鞋说的那样，就是个带状态的函数，每次调用执行不同的功能。
先上一下stackless的coroutine的简单示例：
#include <iostream>
#include <boost/asio/yield.hpp>

int foo(boost::asio::coroutine& ct)
{
    std::cout << "before reenter" << std::endl;

    reenter(ct)
    {
        std::cout << "before yield1" << std::endl;
        yield std::cout << "yield1" << std::endl;
        std::cout << "before yield2" << std::endl;
        yield return 1;
    }

    std::cout << "after reenter" << std::endl;
    return 2;
}

int main(int argc, char* argv[])
{
    boost::asio::coroutine ct;
    while (!ct.is_complete())
    {
        int ret = foo(ct);
        std::cout << "return:" << ret << std::endl;
    }
    return 0;
}

简单来说就是首先会执行reenter之前的代码（打印before reenter），当函数运行到reenter范围内的时候，第一次会执行第一个yield之前的代码
（打印before yield1）和yield关键词之后跟的那个语句（打印 yield1），然后直接跳出reenter范围执行之后的代码（打印after reenter和return 2）；
第二次调用时进入reenter后则会直接从第一个yield下面开始执行，执行到第二个yield结束，因为yield后面接的是一个return语句，
所以reenter范围后面的代码没有执行；当没有yield可以继续执行的时候，就不再进入reenter了。
灰常简单，其实就是个switch case，我都觉得自己用switch case实现个肯定不比这个差。不过这几天学习asio下来发现，asio本身根本就没啥可学习的高级的东西，
都是在学他的思想，虽然只是这么简单的一段代码，换个思维方式可能就会有很大作用，一般在异步程序中使用coroutine就是为了少写一些回调。
如果一个协议里面要有顺序的读写几十次的话，对于同步的操作来说很简单，一路按照协议read、write、read、write下来就行了，但是异步的就不行了，
你必须在上一个read或者write完成的handler中发起下一次的read或者write，协议稍微一复杂，回调函数就会多得让你恶心，这个时候coroutine就派上用场了，
只需要一个回调函数，只要不停的调用就好了，函数会自动的按照你写得yield的顺序执行相应的代码，让代码看起来就像是同步的一样
// asio_sample.cpp : 定义控制台应用程序的入口点。
//

#include <boost/asio.hpp>
#include <boost/bind.hpp>
#include <boost/asio/yield.hpp>
#include <iostream>

boost::asio::io_service ios;
boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(), 1234);
boost::asio::ip::tcp::acceptor acceptor(ios, endpoint);

char data[1024];

void handle(boost::asio::coroutine ct,boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error,size_t bytes_transferred)
{
    if (error)
    {
        std::cout << "read发生错误：" << error.message() << std::endl;
        delete sock;
        return;
    }

    reenter(ct)
    {
        yield boost::asio::async_write(*sock, boost::asio::buffer(data, bytes_transferred),
            boost::bind(handle,ct, sock,
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));

        yield sock->async_read_some(boost::asio::buffer(data),
            boost::bind(handle, boost::asio::coroutine(),sock,
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

}

void session(boost::asio::ip::tcp::socket* sock,
    const boost::system::error_code& error)
{
    if (error)
    {
        delete sock;
    }
    else
    {
        std::cout << "有客户端连接" << std::endl;

        sock->async_read_some(boost::asio::buffer(data),
            boost::bind(handle, boost::asio::coroutine(),sock,
            boost::asio::placeholders::error,
            boost::asio::placeholders::bytes_transferred));
    }

    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s,
        boost::asio::placeholders::error));
}

int main(int argc, char* argv[])
{
    boost::asio::ip::tcp::socket* s = new boost::asio::ip::tcp::socket(ios);
    acceptor.async_accept(*s, boost::bind(session, s, boost::asio::placeholders::error));

    ios.run();
    return 0;
}
客户端断开服务器报错：delete sock; 之后要return

由于自己对OpenSSL和密码学什么的还在白痴状态，所以这里只能记录一下一个简单的流程了——从编译OpenSSL到生成证书，然后在asio里面从内存加载证书文件简历安全连接。
1.编译OpenSSL
这个网上一搜一大堆，不过还是记录下吧。首先到OpenSSL官网下载最新的OpenSSL源码（就别用老的了吧，再遇到个HeartBleed啥的也能减少点危害），随便解压到哪。
下载安装ActivePerl，并加到PATH环境变量中（有的系统加完要重启电脑才能在cmd中执行perl命令）。完成后，打开VS的开发人员命令提示，CD到OpenSSL根目录，执行以下命令：
perl configure VC-WIN32
ms\do_ms
nmake -f ms\nt.mak
nmake -f ms\nt.mak install
注意最后的nmake -f ms\nt.mak install不能少，这个命令会在源码所在的盘的根目录下新建一个usr目录，头文件库文件还有编译好的openssl.
exe都在这个目录里面，而且还有一些配置文件，如果没有这些配置文件，后面生成证书会失败。
如果要编译OpenSSL为dll而不是静态库，把最后两句改成
nmake -f ms\ntdll.mak
nmake -f ms\ntdll.mak install
就好了。如果不出错，OpenSSL就编译完了
2.生成证书 证书这东西我是完全不了解，也完全不知道asio的ssl示例里面的证书是怎么生成的，这个有空还得请教jackarain，再怎么说也是自己发现过OpenSSL的漏洞的人
（好口怕啊...囧），在stackoverflow上找了个[示例][2]（不知道踩了什么bug了，这里的这个超链接加不上，直接贴这里吧.... 
http://stackoverflow.com/questions/6452756/exception-running-boost-asio-ssl-example），这个是在linux下的，windows其实也一样，
把里面 cp server.key server.key.secure 这一句改成 copy server.key server.key.secure 就可以了，然后按照下面说的修改server.cpp和client.cpp就好了，
测试了下么啥问题 3.从内存加载证书 虽然用证书加密了传输内容，但是因为证书暴漏在外面，别人也可以用你的证书来和服务器通信，所以最好是能把证书写到程序里面，
然后加个强壳，虽然也不可能完全阻止破解，但只要破解难度过大，超过了破解后带来的利益，那一般就是安全的了，所以需要从内存加载证书，
静态链接OpenSSL（要不别人hook一下OpenSSL的相关函数，你的证书内容又完全暴露了），然后加强壳（虚拟机壳啥的，要不IDA看一下字符串就看到证书了）。 
废话了这么多，说一下具体该怎么搞吧。貌似老版本的asio没提供直接从内存加载证书的接口，要用OpenSSL自己本身的接口，比较麻烦，
新版本的boost（写文章用的1.55,boost官网里面说是1.54添加的）里面的asio直接有从内存加载证书的接口，很简单，
把几个加载证书文件的接口换一下就可以了 
client.cpp： load_verify_file替换成add_certificate_authority
server.cpp：
use_certificate_chain_file替换成use_certificate_chain
use_private_key_file替换成use_private_key
use_tmp_dh_file替换成use_tmp_dh
除了client里面的那个函数没法通过函数名来联想到，其他的函数都是把原来函数的_file去掉了而已。
这些函数都是把原来要求输入文件名的参数换成了boost::asio::const_buffer，用一个字符串（证书内容）创建个buffer传进去就好了，
另外boost 1.54版本里面的asio添加的关于从内存加载证书的函数一共有六个，具体自己看这里吧。
最后吐槽下我在找asio从内存加载证书的东西时，在stackoverflow上看到有人也在问，不过都没人知道load_verify_file对应的函数是哪个，
我搞明白了之后就注册了个号去回答了一下，结果因为引用了csdn的一片文章（文章内容是转载的一个英文文章，应该不是看不懂的原因），
所以被人踩了，然后标记为删除了..
让我把文章内容贴上去，不知道是不是他们访问不了csdn。后来我发现CSDN那篇文章其实就是转的stackoverflow上的一个回答（我在这篇博文中引用的这个）
